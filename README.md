# k8-llm

Deploys a scalable LLM microservice using Kubernetes.

## Getting started

- Build Docker container: `docker build -t llm-api .`
- Run Docker container: `docker run -p 5001:80 llm-api`
- Access API: [`localhost:5001`](http://localhost:5001)
